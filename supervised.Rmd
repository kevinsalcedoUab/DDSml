---
title: "Supervised Learning"
author: "Humbert Costas"
date: "6/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library("jsonlite", warn.conflicts = FALSE)
library("ggplot2", warn.conflicts = FALSE)
library("lattice", warn.conflicts = FALSE)
library("caret", warn.conflicts = FALSE)
library("gbm", warn.conflicts = FALSE)
library("pROC", warn.conflicts = FALSE)
library(tidyjson)
library(tidyverse)
library(ggplot2)
library(ggraph)

set.seed(42)
```

# Detección de ataques con aprendizaje supervisado

El siguiente ejercicio consiste en crear un modelo entrenado capaz de detectar ataques a partir de logs de un firewall.
Para este propósito, se realizará una prueba de concepto con una pequeña muestra de logs previamente etiquetados como tráfico normal o ataque.

## Data sets

Se proporcionan los siguentes archivos:

 - features.csv
 - events.csv

```{r tidy_data, echo=FALSE}
if (!dir.exists("data")) dir.create("data")
if (!dir.exists("data/raw")) dir.create("data/raw")

events_total <- read.csv("data/raw/events.csv")
features <- read.csv("data/raw/features.csv")
```

### Events analysis

```{r events_stats, echo=FALSE}
events <- events_total[sample(1:nrow(events_total), size = 10000), ]

#ataques mas comunes
events_attacCat <- events %>%
     group_by(attack_cat) %>% 
     tally()

events_attacCat <- as.data.frame(events_attacCat)
events_attacCat <- events_attacCat[-c(1), ]

pie(events_attacCat$n, labels = events_attacCat$attack_cat, main = 'Ataques más comunes')

#protocoles mas comunes
events_prot <- events %>%
     group_by(proto) %>% 
     tally()

events_prot <- as.data.frame(events_prot)

pie(events_prot$n, labels = events_prot$proto, main = 'Protocoles más comunes')

#Intente otros graficos pero no me funcionaban, perdona por tantos quesitos :)

#barplot(events_prot$proto, names = events_prot$n)
#box()

```

### Data enrichment

```{r data_enrich, echo=FALSE}
#IPS que mas atacadas
events_src_ip <- events %>%
     group_by(srcip) %>% 
     filter(Label == 1) %>%
     tally()

pie(events_src_ip$n, labels = events_src_ip$srcip, main = 'IPs de atacantes')

#Puertos mas atacados (podria ser otro grafico)
events_dst_port <- events %>%
     group_by(dsport) %>% 
     filter(Label == 1) %>%
     tally()

pie(events_dst_port$n, labels = events_dst_port$dsport, main = 'puertos más atacados')

#IPs que mas atacan
events_dst_ip <- events %>%
     group_by(dstip) %>% 
     filter(Label == 1) %>%
     tally()

pie(events_dst_ip$n, labels = events_dst_ip$dstip, main = 'IPs más atacadas')

```

## Feature engineering

```{r feat_eng, echo=FALSE}
# El modelo requiere nombres de columna simples y features numericas o factor
names(events) <- stringr::str_replace_all(names(events), "_", "")
events <- as.data.frame(unclass(events), stringsAsFactors = TRUE)

# Etiquetamos la columna Label con valores categoricos
events$Label <- ifelse(events$Label == 1, "ATTACK", "NORMAL")
events$Label <- as.factor(events$Label)

outcomeName <- 'Label'

#Si no se quita esta columna se verá solo que esta columna tiene toda la importancia, ya que esta columna por si misma determina si es un ataque o no.
outcomeName2 <- 'attackcat'
predictorsNames <- names(events)[names(events) != outcomeName & names(events) != outcomeName2]

prop.table(table(events$Label))
```

## Build model

### Create train and test data sets

```{r train_test, echo=FALSE}
splitIndex <- createDataPartition(events[,outcomeName], p = .75, list = FALSE, times = 1)
trainDF <- events[ splitIndex,]
testDF  <- events[-splitIndex,]

```

### Model definition

```{r model_config, echo=FALSE}
objControl <- trainControl(method = 'cv', 
                           number = 3, 
                           returnResamp = 'none', 
                           summaryFunction = twoClassSummary, 
                           classProbs = TRUE)
```

### Train model

```{r model_train, echo=FALSE}
objModel <- train(trainDF[,predictorsNames], trainDF[,outcomeName], 
                  method='gbm', 
                  trControl=objControl,  
                  metric = "ROC",
                  preProc = c("center", "scale"))
summary(objModel)
```

### Test model

```{r model_test, echo=FALSE}
predictions <- predict(object = objModel, testDF[, predictorsNames], type = 'raw')
head(predictions)

```

## Evaluate model

```{r model_eval, echo=FALSE}
print(postResample(pred=predictions, obs=as.factor(testDF[,outcomeName])))

```


```{r predic_prob}
# probabilites 
predictions <- predict(object=objModel, testDF[,predictorsNames], type='prob')
auc <- roc(ifelse(testDF[,outcomeName]=="ATTACK",1,0), predictions[[2]])
print(auc$auc)
```



```{r var_importance}
plot(varImp(objModel,scale=F))
```


## Conclusion
Como se ve en el gráfico el factor más importante es la procedencia de la ip, esto quiere decir que casi siempre es el mismo atacante. Después se refleja que la gran mayoría de ataques son dirigidos a IPs en concreto. No obstante, me gustaría resaltar que estos analisis fueron hecho sobre una muestra sampleada para mejorar la velocidad de ejecución; sin embargo, al ser sampleada aleatoriamente los resultados serian practicamente los mismos que si los datos fueran los completos. 

Para acabar, estos datos podrian ser utilizados para proteger las ips mas vulnerables o atacadas, o también para prohibir la conexión a ciertas IPs. 

```{r conclusion, echo=FALSE}


```


